# ğŸ§  Recurrent Neural Network (RNN) for Twitter Airline Sentiment Analysis

This project implements a **Recurrent Neural Network (RNN)** model using **Long Short-Term Memory (LSTM)** to perform **sentiment classification** on airline-related tweets from Twitter.  
The goal is to classify each tweet as **Positive**, **Neutral**, or **Negative** based on its textual content.

---

ğŸ“Œ **Recommended Environment:**  
> Designed for **Google Colab (CPU/GPU)** users, but compatible with IDEs like **VS Code**, **PyCharm**, or **Jupyter Notebook**.

---

ğŸ‘¤ **Author:** Abdul Manan  
ğŸ§ª *Plant Breeder | Machine & Deep Learning Researcher*  
ğŸ“§ [abdulmanan2287@gmail.com](mailto:abdulmanan2287@gmail.com) | ğŸ”— [LinkedIn](https://www.linkedin.com/in/abdul-manan-0aa546332/) | ğŸ’» [GitHub](https://github.com/manan348)

ğŸ—“ï¸ **Last Updated:** February 2026

---

## ğŸ“‚ Dataset Information

- **Source:** [:contentReference[oaicite:0]{index=0}](https://www.kaggle.com/datasets/crowdflower/twitter-airline-sentiment)
- **License:** [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/legalcode)
- **Description:**  
  Tweets directed at six major U.S. airlines, labeled as *positive*, *neutral*, or *negative*.
- **Objective:**  
  Predict the **sentiment polarity** of tweets related to airline services.

---

## ğŸ¯ Project Objective

> Develop a **deep learning NLP model** using a **Recurrent Neural Network (RNN)** with **Bidirectional LSTM** to accurately classify airline tweets into sentiment categories.  
> The model includes **data balancing**, **text preprocessing**, **emoji handling**, and **hyperparameter tuning** for optimal results.

---

## ğŸ§© Model Performance Summary

| Metric | Value |
|--------|--------|
| **Validation Accuracy** | **0.9141** |
| **Test Accuracy** | **0.9141** |
| **Macro F1-score** | **0.91** |
| **Weighted F1-score** | **0.91** |
| **Negative F1** | 0.89 |
| **Neutral F1** | 0.90 |
| **Positive F1** | 0.95 |

---

### ğŸ“ˆ Model Insights

- **Best Validation Accuracy:** 91.4%  
- **Stable generalization:** Training vs. Validation gap â‰ˆ 4%  
- **High consistency:** Test accuracy matches validation accuracy  
- **Most accurate class:** Positive sentiment (F1 = 0.95)  
- **Most confused classes:** Negative â†” Neutral (common in real tweets)

---

## ğŸ” Exploratory Data Analysis (EDA)

**Visualizations created using `plotly.express`:**
- **Sentiment Distribution:** Shows majority of tweets are *negative* (~63%)  
- **Sentiment per Airline:** Reveals **United** and **US Airways** have most negative tweets  
- **Tweet Length Distribution:** Helps determine max sequence length for RNN tokenization  

ğŸ“Š *Findings:*
- Tweets are short (median length â‰ˆ 15 words)
- Class imbalance: Negative >> Neutral > Positive
- Imbalance addressed with **upsampling**

---

## ğŸ§¹ Text Preprocessing Pipeline

### ğŸ§¾ Cleaning Steps
1. Remove **URLs**, **hashtags**, **mentions (@user)**, and **punctuation**
2. Convert **emojis** to text equivalents (e.g., ğŸ˜Š â†’ "smiling face")
3. Expand **contractions** (e.g., "canâ€™t" â†’ "cannot")
4. Convert to lowercase and strip extra spaces

### âš™ï¸ Tools Used
- `emoji` â€“ for emoji detection and conversion  
- `re` (regex) â€“ for pattern-based cleaning  
- `contractions` â€“ for expanding short forms  
- `LabelEncoder` â€“ for encoding sentiment labels (0 = Negative, 1 = Neutral, 2 = Positive)

---

## âš–ï¸ Dataset Balancing

To mitigate class imbalance:
- Oversampled *Neutral* and *Positive* classes using **:contentReference[oaicite:1]{index=1}**
- Resulting dataset has **equal class distribution** across all sentiments.

---

## ğŸ”¢ Tokenization & Padding

| Parameter | Description | Value |
|------------|--------------|--------|
| **MAX_WORDS** | Vocabulary size | 12,000 |
| **MAX_LEN** | Max tweet length | 50 tokens |
| **Padding Type** | Post | Applied |
| **Tokenizer OOV Token** | `<OOV>` | Used for unseen words |

---

## ğŸ§  Model Architecture (RNN - LSTM)

| Layer | Description |
|--------|-------------|
| **Embedding** | Word embedding (trainable) |
| **Bidirectional LSTM** | Captures forward and backward sequence dependencies |
| **Dense (Softmax)** | 3 output classes (Positive, Neutral, Negative) |

**Optimizer:** Adam  
**Loss:** Sparse Categorical Crossentropy  
**Metrics:** Accuracy  

---

## âš™ï¸ Hyperparameter Tuning

Three models tested with different configurations:

| Model   | Embedding Dim  | LSTM Units  | Dropout  | Batch Size | Epochs |
|---------|----------------|-------------|----------|------------|--------|
| 1       | 32             | 32          | 0.2      | 32         | 5      |
| 2       | 64             | 64          | 0.3      | 64         | 7      |
| 3       | 128            | 128         | 0.3      | 128        | 7      |

**Best Model:** Model 3 â†’ **Validation Accuracy = 91.4%**

### Callbacks Used
- `EarlyStopping(monitor='val_loss', patience=3)`  
- `ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=2)`

---

## ğŸ“Š Results & Visualization

### ğŸŸ¦ Accuracy Curve
- Training accuracy increased steadily to **96%**
- Validation stabilized near **91%** (no overfitting)

### ğŸŸ§ Loss Curve
- Training loss dropped smoothly
- Validation loss plateaued â†’ good regularization

### ğŸ§® Confusion Matrix
| Actual \ Predicted | Negative | Neutral | Positive |
|--------------------|-----------|----------|-----------|
| **Negative** | 1584 | 173 | 80 |
| **Neutral** | 105 | 1618 | 60 |
| **Positive** | 24 | 28 | 1798 |

âœ… Correct predictions dominate diagonals  
âš ï¸ Minor confusion between *Negative* and *Neutral*

---

Install via:

```bash
pip install -r requirements.txt